{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projekt 4 Super k-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Celem projektu jest stworzenie zupełnie nowego zespołowego klasyfikatora k-NN  i porównania jego jakości, czasów jego uczenia i odpowiedzi ze standardowym klasyfikatorem SVM. \n",
    "W nawiasie wymagania na ocenę maksymalną.\n",
    "\n",
    "DoD.\n",
    "Należy sporządzić raport z projektu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Zbiór danych: TNG, ok 18000 próbek, 20 klas. Zbiór danych MNIST (70000 próbek 10 klas). Odnośnie TNG wykorzystujemy gotowe dane reprezentujące tekst blogów w postaci wektorów (dostarcza prowadzący). Dane dekorelujemy wykorzystując transformatę PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Z jednego zbioru danych tworzymy kilka sub-zestawów danych (>=5 <=10) na różnych zestawach cech (maski mogą być losowane w sposób random, ale nie powinny być gęste). Maski mogą mieć różną długość. Prawdopodobieństwo wystąpienia cechy w zestawie może być proporcjonalne do jej istotności (np. mierzonej wielkością wartości własnych po transformacie PCA). Jednak nie może być takiej cechy, która nie dostała się do żadnego zestawu. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Liczymy średnią przynależność każdej próbki do danej klasy na bazie klasyfikatora k-NN dla każdego sub-zestawu danych. Dokonujemy fuzji wyników klasyfikacji (jakiej?) dla każdej próbki po sub-zestawach danych. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Jak zmieni się jakość klasyfikatora w zależności od k?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Wyniki jakości klasyfikatorów oceniać na bazie krzyżowej-walidacji, (accuracy - Loss-błąd, Krzywa ROC, Precision-Recall, (pola pod krzywymi) F1). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.colors as mcolors\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "rows_size = 0.6\n",
    "\n",
    "def divide_dataset(X: np.ndarray,\n",
    "                   y: np.ndarray,\n",
    "                   sub_num: int = 10,\n",
    "                   rows_size: float = 0.6,\n",
    "                   cols_size: float = 0.7):\n",
    "    # get feature importances\n",
    "    tree = ExtraTreesClassifier()\n",
    "    tree.fit(X, y)\n",
    "    feature_importances = tree.feature_importances_\n",
    "    feature_importances /= feature_importances.sum()\n",
    "\n",
    "    # prepare indices\n",
    "    row_indices = list(range(X.shape[0]))\n",
    "    col_indices = list(range(X.shape[1]))\n",
    "    num_rows = round(X.shape[0] * rows_size)\n",
    "    num_cols = round(X.shape[1] * cols_size)\n",
    "\n",
    "    used_cols = set()\n",
    "    subparts = []\n",
    "    col_masks = []\n",
    "    \n",
    "    for i in range(sub_num):\n",
    "        # randomly, uniformly sample rows\n",
    "        rows = np.random.choice(row_indices,\n",
    "                                size=num_rows,\n",
    "                                replace=True)\n",
    "\n",
    "        # randomly sample X columns with probability distribution relative to\n",
    "        # the features' importances\n",
    "        cols = np.random.choice(col_indices,\n",
    "                                size=num_cols,\n",
    "                                replace=False,\n",
    "                                p=feature_importances)\n",
    "        if i == sub_num - 1:\n",
    "            # force usage of columns not used before\n",
    "            used_cols |= set(cols)\n",
    "            not_used_cols = set(col_indices) - used_cols\n",
    "            not_used_cols = np.fromiter(not_used_cols,\n",
    "                                        int,\n",
    "                                        len(not_used_cols))\n",
    "            cols = np.sort(np.concatenate((cols, not_used_cols)))\n",
    "\n",
    "        \n",
    "        X_part = X[rows, :]\n",
    "        X_part = X_part[:, cols]\n",
    "        \n",
    "        y_part = y[rows]\n",
    "\n",
    "        used_cols |= set(cols)\n",
    "        subparts.append((X_part, y_part))\n",
    "        col_masks.append(cols)\n",
    "        \n",
    "    return subparts, col_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def get_classifiers(dataset, n_neighbors): \n",
    "    classifiers = []\n",
    "    for row in dataset:\n",
    "        x, y = row\n",
    "        neigh = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "        neigh.fit(x, y)\n",
    "        classifiers.append(neigh)\n",
    "\n",
    "    return classifiers\n",
    "\n",
    "\n",
    "def super_k_nn(x, divided_train_dataset, classes_count, n_neighbors=3):\n",
    "    \n",
    "    classifiers = get_classifiers(divided_train_dataset[0], n_neighbors)  \n",
    "    masks = divided_train_dataset[1]\n",
    "    result = []\n",
    "    \n",
    "    for row in x:\n",
    "        votes = [0] * classes_count\n",
    "        for i, c in enumerate(classifiers):\n",
    "            \n",
    "            # match shape to train set shape\n",
    "            temp_x = row[masks[i]] \n",
    "            \n",
    "            for prediction in c.predict([temp_x]):\n",
    "                votes[int(prediction)] += 1\n",
    "                   \n",
    "        result.append(str(np.argmax(votes))) \n",
    "\n",
    "    return result, classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml(\"mnist_784\", data_home=\"data/mnist_784\", cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped_mnist = list(zip(mnist.data, mnist.target))\n",
    "mnist_random = random.sample(zipped_mnist, 7000)\n",
    "x, y = zip(*(mnist_random))\n",
    "x = np.asarray(x)\n",
    "y = np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x) \n",
    "\n",
    "pca = PCA(n_components=30)\n",
    "x_pca = pca.fit_transform(x_scaled)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_pca, y, train_size=0.2, test_size=0.02, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 0.9400534629821777 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8857142857142857, 0.8787045158363533)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_divided_dataset = divide_dataset(x_train, y_train, rows_size=rows_size)\n",
    "start = time.time()\n",
    "result = super_k_nn(x_test, mnist_divided_dataset, 10)[0]\n",
    "end = time.time() \n",
    "print(f\"time elapsed: {end - start} s\")\n",
    "accuracy_score(y_true=y_test, y_pred=result), f1_score(y_true=y_test, y_pred=result, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1, accuracy: 0.8785714285714286, f1_score: 0.8738164229493209\n",
      "k: 3, accuracy: 0.8857142857142857, f1_score: 0.8787045158363533\n",
      "k: 5, accuracy: 0.8357142857142857, f1_score: 0.8145703239152289\n",
      "k: 10, accuracy: 0.8642857142857143, f1_score: 0.8495931373590947\n",
      "k: 20, accuracy: 0.8285714285714286, f1_score: 0.8281217619941023\n"
     ]
    }
   ],
   "source": [
    "for i in [1, 3, 5, 10, 20]:\n",
    "    result = super_k_nn(x_test, mnist_divided_dataset, 10, i)[0]\n",
    "    acc = accuracy_score(y_true=y_test, y_pred=result)\n",
    "    f1 = f1_score(y_true=y_test, y_pred=result, average='macro')\n",
    "    print(f\"k: {i}, accuracy: {acc}, f1_score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vs SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (accuracy_score, plot_roc_curve, \n",
    "                             precision_recall_curve, plot_precision_recall_curve, f1_score, average_precision_score, \n",
    "                             hinge_loss, precision_score, recall_score, classification_report)\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.datasets import (load_digits, fetch_openml, load_iris,)\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import stats\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def get_df_row(report): \n",
    "    return pd.DataFrame(report, columns = ['name' ,\n",
    "                                           'accuracy (cross-val)',\n",
    "                                           'accuracy',\n",
    "                                           'precision' ,\n",
    "                                           'recall',\n",
    "                                          ], index=[0])\n",
    "\n",
    "def evaluate_svm(X_train, X_test, y_train, y_test, kernel='linear', C=1):\n",
    "    start = time.time()\n",
    "    classifier =  SVC(kernel=kernel, C=C)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_predicted = classifier.predict(X_test)\n",
    "    end = time.time() \n",
    "    print(f\"time elapsed: {end - start} s\")\n",
    "    report = classification_report(y_test, y_predicted, output_dict=True)['weighted avg']\n",
    "    report['name'] = 'SVM, C = {}, kernel: {}'.format(C, kernel)\n",
    "    report['accuracy'] = report['f1-score']\n",
    "    del report['f1-score']\n",
    "    report['accuracy (cross-val)'] = np.mean(cross_val_score(classifier, X_train, y_train, cv=5, scoring='accuracy'))\n",
    "    return report\n",
    "\n",
    "def evaluate_all(X_train, X_test, y_train, y_test):\n",
    "    base_df = pd.DataFrame( columns = ['name' ,\n",
    "                                       'accuracy (cross-val)',\n",
    "                                       'accuracy',\n",
    "                                       'precision' ,\n",
    "                                       'recall',\n",
    "                                      ])\n",
    "    for C in [1, 5]:\n",
    "        for kernel in ['linear', 'poly', 'rbf', 'sigmoid']:\n",
    "            report = evaluate_svm(X_train, X_test, y_train, y_test, C=C, kernel=kernel)\n",
    "            base_df = pd.concat([base_df,get_df_row(report)], ignore_index=True)\n",
    "    return base_df.sort_values(by='accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml(\"mnist_784\", data_home=\"./mnist_784\", cache=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(mnist.data, mnist.target, train_size=0.008, test_size=0.002, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 0.1760101318359375 s\n",
      "time elapsed: 0.2580146789550781 s\n",
      "time elapsed: 0.31201767921447754 s\n",
      "time elapsed: 0.23401331901550293 s\n",
      "time elapsed: 0.17901039123535156 s\n",
      "time elapsed: 0.24601435661315918 s\n",
      "time elapsed: 0.35102033615112305 s\n",
      "time elapsed: 0.16200900077819824 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>accuracy (cross-val)</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVM, C = 5, kernel: rbf</td>\n",
       "      <td>0.898214</td>\n",
       "      <td>0.864221</td>\n",
       "      <td>0.874909</td>\n",
       "      <td>0.864286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM, C = 1, kernel: rbf</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.847333</td>\n",
       "      <td>0.863135</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM, C = 5, kernel: poly</td>\n",
       "      <td>0.835714</td>\n",
       "      <td>0.830633</td>\n",
       "      <td>0.848176</td>\n",
       "      <td>0.828571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM, C = 1, kernel: linear</td>\n",
       "      <td>0.844643</td>\n",
       "      <td>0.828827</td>\n",
       "      <td>0.840569</td>\n",
       "      <td>0.828571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM, C = 5, kernel: linear</td>\n",
       "      <td>0.844643</td>\n",
       "      <td>0.828827</td>\n",
       "      <td>0.840569</td>\n",
       "      <td>0.828571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM, C = 1, kernel: sigmoid</td>\n",
       "      <td>0.826786</td>\n",
       "      <td>0.783211</td>\n",
       "      <td>0.810759</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVM, C = 5, kernel: sigmoid</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.774343</td>\n",
       "      <td>0.790616</td>\n",
       "      <td>0.778571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM, C = 1, kernel: poly</td>\n",
       "      <td>0.823214</td>\n",
       "      <td>0.761675</td>\n",
       "      <td>0.795958</td>\n",
       "      <td>0.764286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          name  accuracy (cross-val)  accuracy  precision  \\\n",
       "6      SVM, C = 5, kernel: rbf              0.898214  0.864221   0.874909   \n",
       "2      SVM, C = 1, kernel: rbf              0.885714  0.847333   0.863135   \n",
       "5     SVM, C = 5, kernel: poly              0.835714  0.830633   0.848176   \n",
       "0   SVM, C = 1, kernel: linear              0.844643  0.828827   0.840569   \n",
       "4   SVM, C = 5, kernel: linear              0.844643  0.828827   0.840569   \n",
       "3  SVM, C = 1, kernel: sigmoid              0.826786  0.783211   0.810759   \n",
       "7  SVM, C = 5, kernel: sigmoid              0.812500  0.774343   0.790616   \n",
       "1     SVM, C = 1, kernel: poly              0.823214  0.761675   0.795958   \n",
       "\n",
       "     recall  \n",
       "6  0.864286  \n",
       "2  0.850000  \n",
       "5  0.828571  \n",
       "0  0.828571  \n",
       "4  0.828571  \n",
       "3  0.785714  \n",
       "7  0.778571  \n",
       "1  0.764286  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_all(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler_mnist = StandardScaler().fit(X_train)\n",
    "x_train = scaler_mnist.transform(X_train)\n",
    "x_test = scaler_mnist.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 0.19401097297668457 s\n",
      "score=0.842857, f1=0.834900\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "start = time.time() \n",
    "clf = SVC(C=0.1, kernel='linear', )\n",
    "clf.fit(x_train,y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "end = time.time() \n",
    "print(f\"time elapsed: {end - start} s\")\n",
    "\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_true=y_test, y_pred=y_pred, average='macro')\n",
    "print('score=%f, f1=%f' %(score, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "\n",
    "twenty_train = fetch_20newsgroups(shuffle=True, subset='train', random_state=42, categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "twenty_test = fetch_20newsgroups(shuffle=True, subset='test', random_state=42, categories=categories, remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2257\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "x_train = twenty_train.data[:3000]\n",
    "y_train = twenty_train.target[:3000]\n",
    "x_test = twenty_test.data[:600]\n",
    "y_test = twenty_test.target[:600]\n",
    "print(len(x_train))\n",
    "\n",
    "# convert text to vectors\n",
    "vectorizer = TfidfVectorizer()\n",
    "x_train = vectorizer.fit_transform(x_train)\n",
    "x_test = vectorizer.transform(x_test)\n",
    "print(x_train.toarray()[0:2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2257, 28865)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 28865)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn import preprocessing\n",
    "x_train = preprocessing.scale(x_train, with_mean=False)\n",
    "x_test = preprocessing.scale(x_test, with_mean=False)\n",
    "\n",
    "svd = TruncatedSVD(n_components=70)\n",
    "tng_x_train_scaled = svd.fit_transform(x_train)\n",
    "x_test_scaled = svd.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 5.2062976360321045 s\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'predict_proba'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-e6ca288544b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresult_int\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresult_int\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'macro'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifiers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_int\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"k: {i}, accuracy: {acc}, f1_score: {f1}, loss: {loss}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'predict_proba'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "rows_size=0.8\n",
    "tng_divided_dataset = divide_dataset(tng_x_train_scaled, y_train, rows_size=rows_size)\n",
    "\n",
    "for i in [1, 3, 5, 10, 20]:\n",
    "    start = time.time()\n",
    "    result, classifiers = super_k_nn(x_test_scaled, tng_divided_dataset, 4, i)\n",
    "    end = time.time() \n",
    "    print(f\"time elapsed: {end - start} s\")\n",
    "    result_int = [int(x) for x in result]\n",
    "    acc = accuracy_score(y_true=y_test, y_pred=result_int)\n",
    "    f1 = f1_score(y_true=y_test, y_pred=result_int, average='macro')\n",
    "    loss = log_loss(y_test, classifiers.predict_proba(result_int))\n",
    "    print(f\"k: {i}, accuracy: {acc}, f1_score: {f1}, loss: {loss}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vs SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_all(tng_x_train_scaled, x_test_scaled, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
